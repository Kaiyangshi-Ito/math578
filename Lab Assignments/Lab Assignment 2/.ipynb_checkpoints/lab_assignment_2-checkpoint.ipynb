{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH 578 Lab Assignment 2 <a class=\"tocSkip\">\n",
    "\n",
    "\n",
    "***Kai Yang***\n",
    "\n",
    "Original assignment problems are put in *italic fonts*, my text answers are put in **bold fonts**. For both parts, the functions written are in the constructed classes. \n",
    "\n",
    "Another interesting thing to note is that, to run the entire thing on GPU, simply use `cupy` instead of `numpy` -- but for the purpose of the assignment, we will stay with `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T02:29:52.931975Z",
     "start_time": "2020-10-30T02:29:50.931675Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "\n",
    "*Implement a function that computes a QR factorization of a given $n\\times n$ matrix. You can use either Householder reﬂections or Givens rotations. Do a post-processing to make sure that the diagonal entries of the triangular factor $R$ are nonnegative (This requirement makes the factorization unique). Test it on a number of cases to be sure of its correctness.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "\n",
    "*Write a function that generates random orthogonal matrices. This can be done by ﬁrst generating a random matrix $A$, say, with normally distributed entries, and then taking the $Q$-factor of its QR factorization with nonpositive entries on the diagonal of $R$.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "\n",
    "*By modifying your QR factorization code, implement a function that reduces a given $n\\times n$ matrix into a Hessenberg form by orthogonal transformations. Implement also a function that turns a given real symmetric matrix into a tridiagonal form. You may want to add a line that forces the output matrix to be exactly symmetric and tridiagonal. Test the functions on a number of cases.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 \n",
    "\n",
    "*Write a code that performs the QR algorithm on a given real symmetric tridiagonal matrix. Produce 3 versions: no shift (i.e., basic QR), the Rayleigh quotient shift, and the Wilkinson shift. For greater eﬃciency, you may want to modify your QR factorization code so that it takes advantage of the tridiagonality (and perhaps symmetry as well). You may also wish to enforce exact symmetry and tridiagonality at each step of the QR algorithm.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 \n",
    "\n",
    "*Generate a symmetric random matrix with a given set of eigenvalues as $A = Q^T\\Lambda Q$, where $Q$ is a random orthogonal matrix, and $\\Lambda$ is a diagonal matrix (for example, take $\\Lambda = \\text{diag}\\left(1, 2, . . . , 10\\right)$). Please set a ﬁxed seed for the random number generator for reproducibility. Reduce $A$ to a tridiagonal form, and run the QR algorithm on it, by using the functions you implemented. Pick several of the eigenvalues that represent variety of possibilities (that is, one small eigenvalue, one mid-sized eigenvalue, etc.), including the largest eigenvalue, and plot the corresponding errors (in log-scale) against the iteration number. Moreover, plot the size (in log-scale) of the oﬀ-diagonal entries that are close to the position of the chosen eigenvalues against the iteration number. Do this for all 3 versions of the QR algorithm. Comment on your results.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 \n",
    "\n",
    "*Repeat the previous exercise to experiment with interesting situations such as negative eigenvalues, multiple eigenvalues, clustered eigenvalues, singular matrices, extremely small eigenvalues, extremely large eigenvalues, etc.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7 \n",
    "\n",
    "*Now set things up so that the last row and column of $A$ is removed and the QR algorithm is recursively applied to the “cropped” matrix once the last oﬀ-diagonal entry is small enough (say, $\\left|A_{n,n-1}\\right|<10^{-10}$). This way, all eigenvalues can supposedly be computed quickly. Plot $\\left|A_{n,n-1}\\right|$ as well as the error of the corresponding eigenvalue (that is, $\\left|\\lambda_n - A_{n,n-1}\\right|$) against the iteration number. Note that the variable n here takes diﬀerent values in diﬀerent stages as the matrix is cropped to become smaller and smaller. Use a log-log scale for the vertical axis. Do this for all 3 versions of the QR algorithm. Experiment with some interesting combinations of eigenvalues. Comment on your results.*\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "mes",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
